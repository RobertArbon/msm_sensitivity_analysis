{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85127db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rzhu/miniconda3/envs/msm_opt/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cf798443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein = 'CLN'\n",
    "protein = 'BBA'\n",
    "\n",
    "#lag = 31\n",
    "lag = 41\n",
    "process = 2\n",
    "\n",
    "# best_hp_ix = [74, 24, 6]\n",
    "best_hp_ix = [24]\n",
    "\n",
    "# summary_paths = [f'../{protein}/summary.h5']\n",
    "summary_paths = [f'../{protein}/summary_batch1.h5']\n",
    "\n",
    "# hp_paths = ['../../../hpsample_stride1.h5']\n",
    "hp_paths = [f'../{protein}/hpsample.h5']\n",
    "\n",
    "db_name = protein\n",
    "storage_name = \"sqlite:///../{}/{}.db\".format(protein, db_name)\n",
    "study_name = 'gap-ev2ev3_vampeq2'\n",
    "new_gamma = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "83704358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/evs', '/timescale_gradient', '/timescale_ratio', '/timescales', '/vampeq2', '/vamps']\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('../BBA/summary_batch1.h5') as f: \n",
    "    print(f.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a21f10d",
   "metadata": {},
   "source": [
    "---\n",
    "### Create a new study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "319b8be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68711, 7) (140, 14) (68711, 7) (1617, 7)\n",
      "\n",
      " (62665, 29)\n"
     ]
    }
   ],
   "source": [
    "hps = []\n",
    "ts = []\n",
    "gaps = []\n",
    "vampeq2 = []\n",
    "\n",
    "for batch_num in range(1):\n",
    "    \n",
    "    # Hp definitions\n",
    "    hp = pd.read_hdf(hp_paths[batch_num])\n",
    "    hp.reset_index(inplace=True)    \n",
    "    \n",
    "    # Drop these columns if they exist. \n",
    "    for drop_col in ['index', 'Group']:\n",
    "        if drop_col in hp.columns:\n",
    "            hp.drop(labels=[drop_col], inplace=True, axis=1)\n",
    "    hps.append(hp)\n",
    "    \n",
    "    \n",
    "    # timescales\n",
    "    tmp = pd.read_hdf(summary_paths[batch_num], key='timescales')\n",
    "    tmp.reset_index(inplace=True)\n",
    "    \n",
    "    # Drop these columns if they exist. \n",
    "    for drop_col in ['index', 'Group']:\n",
    "        if drop_col in tmp.columns:\n",
    "            tmp.drop(labels=[drop_col], inplace=True, axis=1)\n",
    "    tmp.rename(columns = {'median':'median_ts',\n",
    "                          'lb':'lb_ts',\n",
    "                          'ub':'ub_ts',\n",
    "                          'count':'count_ts'}, inplace=True)\n",
    "    ts.append(tmp)\n",
    "\n",
    "    \n",
    "    # gaps\n",
    "    tmp = pd.read_hdf(summary_paths[batch_num], key='timescale_ratio')\n",
    "    tmp.reset_index(inplace=True)\n",
    "    \n",
    "    # Drop these columns if they exist. \n",
    "    for drop_col in ['index', 'Group']:\n",
    "        if drop_col in tmp.columns:\n",
    "            tmp.drop(labels=[drop_col], inplace=True, axis=1)\n",
    "    tmp.rename(columns = {'median':'median_gap',\n",
    "                          'lb':'lb_gap',\n",
    "                          'ub':'ub_gap',\n",
    "                          'count':'count_gap'}, inplace=True)\n",
    "    gaps.append(tmp)    \n",
    "    \n",
    "    \n",
    "    # vampeq2\n",
    "    tmp = pd.read_hdf(summary_paths[batch_num], key='vampeq2')\n",
    "    tmp.reset_index(inplace=True)\n",
    "    \n",
    "    # Drop these columns if they exist. \n",
    "    for drop_col in ['index', 'Group']:\n",
    "        if drop_col in tmp.columns:\n",
    "            tmp.drop(labels=[drop_col], inplace=True, axis=1)\n",
    "    tmp.rename(columns = {'median':'median_vampeq2',\n",
    "                          'lb':'lb_vampeq2',\n",
    "                          'ub':'ub_vampeq2',\n",
    "                          'count':'count_vampeq2'}, inplace=True)\n",
    "    vampeq2.append(tmp)    \n",
    "\n",
    "hps = pd.concat(hps, axis=0)                  \n",
    "ts = pd.concat(ts, axis=0)\n",
    "gaps = pd.concat(gaps, axis=0)\n",
    "vampeq2 = pd.concat(vampeq2, axis=0)    \n",
    "\n",
    "print(ts.shape, hps.shape, gaps.shape, vampeq2.shape)\n",
    "\n",
    "data = hps.merge(ts, on=['hp_ix'], how='left')\n",
    "data = data.merge(gaps, on=['hp_ix', 'lag', 'process'], how='left')\n",
    "data = data.merge(vampeq2, on=['hp_ix', 'lag', 'process'], how='left')\n",
    "\n",
    "data['feature'] = data.apply(lambda x: f\"{x['feature__value']}\" if x['feature__value'] =='dihedrals' else f\"{x['distances__transform']}-{x['feature__value']}\", axis=1)\n",
    "data.drop_duplicates(inplace=True)\n",
    "print('\\n', data.shape)\n",
    "data.sort_values(by=['hp_ix', 'lag', 'process'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "34450799",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-10 13:41:31,663]\u001b[0m Using an existing study with name 'gap-ev2ev3_vampeq2' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# We may change the default gamma function\n",
    "def hyperopt_gamma(x: int) -> int:\n",
    "    return min(int(np.ceil(0.25 * np.sqrt(x))), 13)\n",
    "\n",
    "hyperopt_parameters = TPESampler.hyperopt_parameters()\n",
    "if new_gamma: hyperopt_parameters['gamma'] = hyperopt_gamma\n",
    "\n",
    "sampler = TPESampler(**TPESampler.hyperopt_parameters(), multivariate=True)\n",
    "\n",
    "study = optuna.create_study(study_name=study_name, \n",
    "                            sampler=sampler, \n",
    "                            storage=storage_name, \n",
    "                            directions=[\"maximize\",\"maximize\"], \n",
    "#                            direction='maximize',\n",
    "                            load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "54a01236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 29)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_add = data.loc[(data.lag==lag) & (data.process==process) , :]\n",
    "\n",
    "# add the following to exclude the best trials\n",
    "# & (~data.hp_ix.isin(best_hp_ix))\n",
    "\n",
    "data_to_add.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4e2c8f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_by_param = {}\n",
    "dist_by_param['steepness'] = optuna.distributions.FloatDistribution(high=50.0, log=False, low=1.0)\n",
    "dist_by_param['centre'] = optuna.distributions.FloatDistribution(high=1.5, log=False, low=0.2)\n",
    "\n",
    "dist_by_param['feature'] = optuna.distributions.CategoricalDistribution(['dihedrals', 'distances'])\n",
    "dist_by_param['transform'] = optuna.distributions.CategoricalDistribution(['logistic', 'linear'])\n",
    "dist_by_param['scheme'] = optuna.distributions.CategoricalDistribution(['ca', 'closest-heavy'])\n",
    "\n",
    "dist_by_param['tica_lag'] = optuna.distributions.IntDistribution(high=100, log=False, low=1)\n",
    "dist_by_param['tica_dim'] = optuna.distributions.IntDistribution(high=20, log=False, low=1)\n",
    "dist_by_param['n_clusters'] = optuna.distributions.IntDistribution(high=500, log=False, low=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "17e8c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in data_to_add.groupby(['hp_ix']):\n",
    "    \n",
    "    assert v.shape[0] == 1\n",
    "    \n",
    "    params = {}\n",
    "    distributions = {}\n",
    "    \n",
    "    params['feature'] = v['feature__value'].values[0]\n",
    "    distributions['feature'] = deepcopy(dist_by_param['feature'])\n",
    "    \n",
    "    if v['feature__value'].values[0] == 'distances': \n",
    "        params['transform'] = v['distances__transform'].values[0]\n",
    "        distributions['transform'] = deepcopy(dist_by_param['transform'])\n",
    "        \n",
    "        params['scheme'] = v['distances__scheme'].values[0]\n",
    "        distributions['scheme'] = deepcopy(dist_by_param['scheme'])\n",
    "\n",
    "        if params['transform'] == 'logistic': \n",
    "            params['centre'] = v['distances__centre'].values[0]\n",
    "            distributions['centre'] = deepcopy(dist_by_param['centre'])\n",
    "\n",
    "            params['steepness'] = v['distances__steepness'].values[0]\n",
    "            distributions['steepness'] = deepcopy(dist_by_param['steepness'])\n",
    "\n",
    "    params['tica_lag'] = v['tica__lag'].values[0]\n",
    "    distributions['tica_lag'] = deepcopy(dist_by_param['tica_lag'])\n",
    "    \n",
    "    params['tica_dim'] = v['tica__dim'].values[0]\n",
    "    distributions['tica_dim'] = deepcopy(dist_by_param['tica_dim'])\n",
    "\n",
    "    params['n_clusters'] = v['cluster__k'].values[0]\n",
    "    distributions['n_clusters'] = deepcopy(dist_by_param['n_clusters'])\n",
    "    \n",
    "    # Median x: timescale \n",
    "    # Median y: process 2/3 timescale ratio\n",
    "    \n",
    "    study.add_trial(optuna.trial.create_trial(\n",
    "        params=params, \n",
    "        distributions=distributions, \n",
    "        values = [v['median_gap'].values[0], v['median_vampeq2'].values[0]]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0e0d340e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': CategoricalDistribution(choices=('dihedrals', 'distances')),\n",
       " 'tica_lag': IntDistribution(high=100, log=False, low=1, step=1),\n",
       " 'tica_dim': IntDistribution(high=20, log=False, low=1, step=1),\n",
       " 'n_clusters': IntDistribution(high=500, log=False, low=10, step=1)}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials[10].distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec18058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msm_opt",
   "language": "python",
   "name": "msm_opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

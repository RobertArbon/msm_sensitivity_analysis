{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "221e1d3e-bcc1-429a-b197-94617749e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9d765728-563d-47e9-90e6-a8dca43c769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = '1fme'\n",
    "lag = 41\n",
    "process = 3\n",
    "\n",
    "\n",
    "summary_paths = [f'../{protein}/summary_batch1.h5', f'../{protein}/summary_batch2.h5', f'../{protein}/summary_batch3.h5']\n",
    "\n",
    "hp_paths = ['../../experiments/hpsample.h5', '../../experiments/new_hpsample.h5', '../../experiments/new_ts_hpsample_missing_best.h5']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "aa590642-2e65-493b-9423-9e0ff5cbdec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/eigenvalue_ratio', '/eigenvalues', '/timescale_gradient', '/timescale_ratio', '/timescales', '/vamp_eqs', '/vamps']\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(summary_paths[0]) as f: \n",
    "    print(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4f0a7e1d-d4e1-46d5-99e8-921ba014bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62661, 7) (140, 14) (61165, 7)\n",
      "(62661, 25)\n",
      "(62661, 25)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hps = []\n",
    "veqs = []\n",
    "gaps = []\n",
    "for batch_num in range(1):\n",
    "    \n",
    "    # Hp definitions\n",
    "    hp = pd.read_hdf(hp_paths[batch_num])\n",
    "    hp.reset_index(inplace=True)    \n",
    "    \n",
    "    # Drop these columns if they exist. \n",
    "    for drop_col in ['index', 'Group']:\n",
    "        if drop_col in hp.columns:\n",
    "            hp.drop(labels=[drop_col], inplace=True, axis=1)\n",
    "\n",
    "    hps.append(hp)\n",
    "    \n",
    "    # timescales\n",
    "    tmp = pd.read_hdf(summary_paths[batch_num], key='vamp_eqs')\n",
    "    tmp.reset_index(inplace=True)\n",
    "    \n",
    "    # Drop these columns if they exist. \n",
    "    for drop_col in ['index', 'Group']:\n",
    "        if drop_col in tmp.columns:\n",
    "            tmp.drop(labels=[drop_col], inplace=True, axis=1)\n",
    "    veqs.append(tmp)\n",
    "\n",
    "    \n",
    "    # gaps\n",
    "    tmp = pd.read_hdf(summary_paths[batch_num], key='eigenvalue_ratio')\n",
    "    tmp.reset_index(inplace=True)\n",
    "    \n",
    "    # Drop these columns if they exist. \n",
    "    for drop_col in ['index', 'Group']:\n",
    "        if drop_col in tmp.columns:\n",
    "            tmp.drop(labels=[drop_col], inplace=True, axis=1)\n",
    "    gaps.append(tmp)    \n",
    "       \n",
    "        \n",
    "        \n",
    "veqs = pd.concat(veqs, axis=0)\n",
    "gaps = pd.concat(gaps, axis=0)\n",
    "hps = pd.concat(hps, axis=0)    \n",
    "\n",
    "print(veqs.shape, hps.shape, gaps.shape)\n",
    "\n",
    "data = veqs.merge(hps, on=['hp_ix'], how='left')\n",
    "data = data.merge(gaps, on=['hp_ix', 'lag', 'process'], how='left')\n",
    "\n",
    "data['feature'] = data.apply(lambda x: f\"{x['feature__value']}\" if x['feature__value'] =='dihedrals' else f\"{x['distances__transform']}-{x['feature__value']}\", axis=1)\n",
    "print(data.shape)\n",
    "data.drop_duplicates(inplace=True)\n",
    "print(data.shape)\n",
    "\n",
    "\n",
    "data.sort_values(by=['hp_ix', 'lag', 'process'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "76a55a93-0c4d-46ec-83bf-7dbd6efe9e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-16 16:09:50,724]\u001b[0m A new study created in RDB with name: k3_ev-gap_vamp_eq\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "db_name = \"1fme\" \n",
    "storage_name = \"sqlite:///{}.db\".format(db_name)\n",
    "study_name = 'k3_ev-gap_vamp_eq'\n",
    "\n",
    "\n",
    "sampler = TPESampler(**TPESampler.hyperopt_parameters())\n",
    "\n",
    "study = optuna.create_study(study_name=study_name, \n",
    "                            sampler=sampler, \n",
    "                            storage=storage_name, \n",
    "                            directions=[\"maximize\", \"maximize\"], \n",
    "                            load_if_exists=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ab59fb60-9881-496e-876c-2a3276f6465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-16 16:09:52,983]\u001b[0m Using an existing study with name '1fme-k3-bs' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "old_study = optuna.create_study(storage='sqlite:///1fme-k3-bs-ts_gap-vamp_eq.db', \n",
    "                                study_name='1fme-k3-bs', load_if_exists=True, \n",
    "                              directions=[\"maximize\", \"maximize\"], \n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "28accb32-a423-45e7-9e83-c3e686b2b1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hp_ix</th>\n",
       "      <th>lag</th>\n",
       "      <th>process</th>\n",
       "      <th>median_x</th>\n",
       "      <th>lb_x</th>\n",
       "      <th>ub_x</th>\n",
       "      <th>count_x</th>\n",
       "      <th>cluster__max_iter</th>\n",
       "      <th>cluster__stride</th>\n",
       "      <th>tica__dim</th>\n",
       "      <th>...</th>\n",
       "      <th>dihedrals__which</th>\n",
       "      <th>distances__scheme</th>\n",
       "      <th>distances__transform</th>\n",
       "      <th>distances__steepness</th>\n",
       "      <th>distances__centre</th>\n",
       "      <th>median_y</th>\n",
       "      <th>lb_y</th>\n",
       "      <th>ub_y</th>\n",
       "      <th>count_y</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>2.878183</td>\n",
       "      <td>2.821447</td>\n",
       "      <td>2.938427</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.016917</td>\n",
       "      <td>1.001594</td>\n",
       "      <td>1.050878</td>\n",
       "      <td>100.0</td>\n",
       "      <td>dihedrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>2.895593</td>\n",
       "      <td>2.831730</td>\n",
       "      <td>2.939413</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>closest-heavy</td>\n",
       "      <td>logistic</td>\n",
       "      <td>18.519573</td>\n",
       "      <td>0.24964</td>\n",
       "      <td>1.021067</td>\n",
       "      <td>1.003773</td>\n",
       "      <td>1.048565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>logistic-distances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>2.724913</td>\n",
       "      <td>2.617577</td>\n",
       "      <td>2.804595</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>closest-heavy</td>\n",
       "      <td>logistic</td>\n",
       "      <td>38.533821</td>\n",
       "      <td>0.23019</td>\n",
       "      <td>1.023588</td>\n",
       "      <td>1.003490</td>\n",
       "      <td>1.066858</td>\n",
       "      <td>100.0</td>\n",
       "      <td>logistic-distances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>2.892029</td>\n",
       "      <td>2.842187</td>\n",
       "      <td>2.950856</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ca</td>\n",
       "      <td>logistic</td>\n",
       "      <td>32.429605</td>\n",
       "      <td>0.55326</td>\n",
       "      <td>1.008437</td>\n",
       "      <td>1.002085</td>\n",
       "      <td>1.025764</td>\n",
       "      <td>100.0</td>\n",
       "      <td>logistic-distances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>2.839644</td>\n",
       "      <td>2.774408</td>\n",
       "      <td>2.937107</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.014646</td>\n",
       "      <td>1.001560</td>\n",
       "      <td>1.056166</td>\n",
       "      <td>100.0</td>\n",
       "      <td>dihedrals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hp_ix  lag  process  median_x      lb_x      ub_x  count_x  \\\n",
       "201       0   41        3  2.878183  2.821447  2.938427      100   \n",
       "699       1   41        3  2.895593  2.831730  2.939413      100   \n",
       "1024      2   41        3  2.724913  2.617577  2.804595      100   \n",
       "1426      3   41        3  2.892029  2.842187  2.950856      100   \n",
       "1837      4   41        3  2.839644  2.774408  2.937107      100   \n",
       "\n",
       "      cluster__max_iter  cluster__stride  tica__dim  ...  dihedrals__which  \\\n",
       "201                1000               10         19  ...               all   \n",
       "699                1000               10          4  ...               NaN   \n",
       "1024               1000               10         18  ...               NaN   \n",
       "1426               1000               10          4  ...               NaN   \n",
       "1837               1000               10         15  ...               all   \n",
       "\n",
       "      distances__scheme  distances__transform  distances__steepness  \\\n",
       "201                 NaN                   NaN              0.000000   \n",
       "699       closest-heavy              logistic             18.519573   \n",
       "1024      closest-heavy              logistic             38.533821   \n",
       "1426                 ca              logistic             32.429605   \n",
       "1837                NaN                   NaN              0.000000   \n",
       "\n",
       "     distances__centre  median_y      lb_y      ub_y  count_y  \\\n",
       "201            0.00000  1.016917  1.001594  1.050878    100.0   \n",
       "699            0.24964  1.021067  1.003773  1.048565    100.0   \n",
       "1024           0.23019  1.023588  1.003490  1.066858    100.0   \n",
       "1426           0.55326  1.008437  1.002085  1.025764    100.0   \n",
       "1837           0.00000  1.014646  1.001560  1.056166    100.0   \n",
       "\n",
       "                 feature  \n",
       "201            dihedrals  \n",
       "699   logistic-distances  \n",
       "1024  logistic-distances  \n",
       "1426  logistic-distances  \n",
       "1837           dihedrals  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_add = data.loc[(data.lag==lag) & (data.process==process), :]\n",
    "data_to_add.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6f0c372b-ef72-4af1-b728-9566ba00f502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6283273776683507, 0.2069380916635079)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_add.loc[data_to_add.feature == 'logistic-distances', 'distances__steepness'].min(), data_to_add.loc[data_to_add.feature == 'logistic-distances', 'distances__centre'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "54119881-59af-4403-a6a0-c453a0f4555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_by_param = old_study.trials[10].distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a51acff9-c70b-4765-8398-aabfb507d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_by_param['steepness'] = optuna.distributions.FloatDistribution(high=50.0, log=False, low=1.0)\n",
    "dist_by_param['centre'] = optuna.distributions.FloatDistribution(high=1.5, log=False, low=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "abd98a4b-84f0-4d21-a4e4-686352a4950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in data_to_add.groupby(['hp_ix']):\n",
    "    \n",
    "    assert v.shape[0] == 1\n",
    "    \n",
    "    params = {}\n",
    "    distributions = {}\n",
    "    \n",
    "    params['feature'] = v['feature__value'].values[0]\n",
    "    distributions['feature'] = deepcopy(dist_by_param['feature'])\n",
    "    \n",
    "    if v['feature__value'].values[0] == 'distances': \n",
    "        params['transform'] = v['distances__transform'].values[0]\n",
    "        distributions['transform'] = deepcopy(dist_by_param['transform'])\n",
    "        \n",
    "        params['scheme'] = v['distances__scheme'].values[0]\n",
    "        distributions['scheme'] = deepcopy(dist_by_param['scheme'])\n",
    "\n",
    "        if params['transform'] == 'logistic': \n",
    "            params['centre'] = v['distances__centre'].values[0]\n",
    "            distributions['centre'] = deepcopy(dist_by_param['centre'])\n",
    "\n",
    "            params['steepness'] = v['distances__steepness'].values[0]\n",
    "            distributions['steepness'] = deepcopy(dist_by_param['steepness'])\n",
    "\n",
    "    params['tica_lag'] = v['tica__lag'].values[0]\n",
    "    distributions['tica_lag'] = deepcopy(dist_by_param['tica_lag'])\n",
    "    \n",
    "    params['tica_dim'] = v['tica__dim'].values[0]\n",
    "    distributions['tica_dim'] = deepcopy(dist_by_param['tica_dim'])\n",
    "\n",
    "    params['n_clusters'] = v['cluster__k'].values[0]\n",
    "    distributions['n_clusters'] = deepcopy(dist_by_param['n_clusters'])\n",
    "    \n",
    "    study.add_trial(optuna.trial.create_trial(\n",
    "        params=params, \n",
    "        distributions=distributions, \n",
    "        values = [v['median_x'].values[0], v['median_y'].values[0]]\n",
    "    \n",
    "    ))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4dbf7-8de6-42b8-8d0e-711644ad4ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
